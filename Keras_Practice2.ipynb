{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwZQnQdAxqYbn10BB9u+ic",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nicsdiary/test-repo/blob/main/Keras_Practice2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "R60jfRHad5as"
      },
      "outputs": [],
      "source": [
        "#데이터를 가져오는 부분\n",
        "\n",
        "from keras.datasets import boston_housing\n",
        "(train_data,train_labels),(test_data,test_labels)=boston_housing.load_data()\n",
        "\n",
        "#Keras 라이브러리에서 Boston Housing 데이터셋을 불러와서, 학습 데이터와 레이블, 테스트 데이터와 레이블을 각각 train_data, train_labels, test_data, test_labels 변수에 저장하는 코드"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)\n",
        "print(test_data.shape)\n",
        "\n",
        "#train_data와 test_data의 크기(shape)를 출력하는 코드입니다. \n",
        "# train_data는 404개의 샘플과 13개의 feature로 이루어진 2D 배열이며,\n",
        "# test_data는 102개의 샘플과 13개의 feature로 이루어진 2D 배열입니다. \n",
        "#각각의 feature는 보스턴 지역의 주택 가격 예측 모델을 위한 입력값"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAp08_pZelny",
        "outputId": "2cb06540-7ee1-4e11-ae7a-b9248a987212"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(404, 13)\n",
            "(102, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[0])\n",
        "\n",
        "#첫 번째 훈련 데이터의 특성 값들을 출력하는 코드"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMqh1mtafBme",
        "outputId": "006f253c-74e8-498d-aca6-8674b3ba2db5"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
            "   3.9769    4.      307.       21.      396.9      18.72   ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "mean = train_data.mean(axis=0)\n",
        "train_data -= mean   #train_data = train_data - mean 과 같은 표현 \n",
        "std = train_data.std(axis=0)\n",
        "\n",
        "\n",
        "#데이터 전처리를 위한 Scaling 작업을 수행하는 코드\n",
        "\n",
        "#train_data.mean(axis=0) : train_data의 열(axis=0) 별 평균값을 계산하여 변수 mean에 저장합니다.\n",
        "#train_data -= mean : train_data에서 평균값(mean)을 빼서 중심을 0으로 만듭니다. \n",
        "#이는 각 특성(feature)의 중앙이 0이 되도록 만들어 줍니다. 이때, -= 연산자를 사용하여 train_data를 업데이트 합니다.\n",
        "#train_data.std(axis=0) : train_data의 열(axis=0) 별 표준편차를 계산하여 변수 std에 저장합니다. \n",
        "#이는 각 특성(feature)의 분포가 비슷하도록 만들어 줍니다."
      ],
      "metadata": {
        "id": "IzoNnBisfEaG"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 구성 \n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "def build_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1])))\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='rmsprop',\n",
        "                loss='mse',\n",
        "                metrics=['mse'])\n",
        "  return model\n",
        "\n",
        "\n",
        "  # models.Sequential()로 모델 객체를 생성하고, model.add()로 층(layer)을 추가해나가는 방식으로 모델을 구성\n",
        "  # 이 모델은 3개의 층으로 이루어져 있습니다. \n",
        "  # 첫 번째 층은 입력 데이터의 크기를 정의하기 위한 input_shape 파라미터와 64개의 유닛을 가진 fully-connected 층(layers.Dense(64))으로 구성되어있음, 활성화 함수로 ReLU를 사용합니다. \n",
        "  # 두 번째 층은 64개의 유닛을 가진 fully-connected 층(layers.Dense(64))으로 구성되어 있으며, 활성화 함수로 ReLU를 사용합니다. \n",
        "  # 마지막 층은 하나의 출력 유닛만을 가진 fully-connected 층(layers.Dense(1))으로 구성되어 있습니다. \n",
        "  # 이 모델은 optimizer='rmsprop'로 RMSprop 최적화 알고리즘을 사용하며, 손실 함수(loss function)로는 MSE(mean squared error)를 사용합니다\n",
        "  # 모델의 성능 평가를 위해 MSE를 모니터링합니다. 마지막으로, 구성된 모델 객체를 반환"
      ],
      "metadata": {
        "id": "zqgSsz5tiKKk"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-folder 검증을 사용한 훈련 검증 \n",
        "\n",
        "import numpy as np \n",
        "\n",
        "k = 4                                       # folder 개수\n",
        "num_val_samples = len(train_data) // k      # 한 folder의 데이터 수 \n",
        "all_scores = []\n",
        "\n",
        "\n",
        "for i in range(k):\n",
        "  print('처리중인 폴드 #', i)\n",
        "\n",
        "\n",
        "  #검증 데이터의 준비 \n",
        "  val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "  val_labels = train_labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "  # K-folder 검증(k-fold cross validation)을 사용하여 훈련 검증하는 방법을 구현\n",
        "  # K-folder 검증은 모델을 검증하기 위해 데이터를 K개의 folder로 나누고, 각 folder를 순차적으로 검증에 사용하고 나머지 folder로 모델을 훈련하는 방식입니다. \n",
        "  # 이를 K번 반복하여 모든 folder가 검증에 사용\n",
        "\n",
        "  # 위 코드에서는 K를 4로 설정하고, train_data의 총 데이터 수를 K로 나누어서 한 folder의 데이터 수를 계산합니다. \n",
        "  # for 루프를 이용하여 K개의 folder를 순차적으로 선택하여 검증 데이터(val_data)와 검증 레이블(val_labels)을 설정\n",
        "  # 이 데이터와 레이블을 이용하여 모델을 검증하고 결과를 all_scores 리스트에 추가\n",
        "\n",
        "  #학습 데이터의 준비\n",
        "  data1 = train_data[:i * num_val_samples]\n",
        "  data2 = train_data[(i+1) * num_val_samples :]\n",
        "  data1_labels = train_labels[:i * num_val_samples]\n",
        "  data2_labels = train_labels[(i+1) * num_val_samples :]\n",
        "\n",
        "  partial_train_data = np.concatenate([data1, data2], axis=0)\n",
        "  partial_train_labels = np.concatenate([data1_labels, data2_labels], axis=0)\n",
        "\n",
        "  # data1은 train_data에서 0부터 i번째 폴드의 시작 인덱스 전까지의 데이터를 의미\n",
        "  # data2는 i번째 폴드의 시작 인덱스부터 i+1번째 폴드의 시작 인덱스 전까지의 데이터를 의미\n",
        "  # print(0, i * num_val_samples)와 print(i * num_val_samples, (i+1) * num_val_samples)\n",
        "  # => 각 폴드의 데이터가 어디서부터 어디까지인지를 확인하기 위한 디버깅용 출력\n",
        "  # partial_train_data는 data1과 data2를 axis=0 방향으로 합친 것으로, i번째 폴드를 제외한 나머지 폴드의 데이터를 훈련 데이터로 사용\n",
        "\n",
        "\n",
        "  #폴드(fold)란 기계 학습에서 교차 검증(cross-validation)을 수행할 때, 전체 데이터를 일정한 크기의 '폴드' 혹은 '파티션'으로 나누어서 검증을 수행하는 단위를 말합니다.\n",
        "  # 즉, 전체 데이터를 k개의 폴드로 나누어서 각각의 폴드를 검증 데이터(validation data)로 사용하고, 나머지 폴드를 훈련 데이터(training data)로 사용하는 것입니다. \n",
        "  #이 때, k개의 폴드로 나누는 것을 k-fold 교차 검증\n",
        "\n",
        " # 모델의 학습\n",
        "  model = build_model()\n",
        "  model.summary()\n",
        "\n",
        "  model.fit(partial_train_data, partial_train_labels, epochs=500, batch_size=128, verbose=0)\n",
        "\n",
        "  val_mse, val_mae = model.evaluate(val_data, val_labels)\n",
        "  print(val_mse, val_mae)\n",
        "  all_scores.append(val_mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "uq7cbLE-2R9z",
        "outputId": "a52dc388-3b3e-4d52-9593-81dd45049e29"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "처리중인 폴드 # 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-e289ed4a9942>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m  \u001b[0;31m# 모델의 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-108-67785e06209f>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/dtensor/utils.py\u001b[0m in \u001b[0;36m_wrap_function\u001b[0;34m(layer_instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlayout_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariable_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_layout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0minit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# Inject the layout parameter after the invocation of __init__()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/core/dense.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     ):\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m                 \u001b[0mbatch_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_shape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_input_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
          ]
        }
      ]
    }
  ]
}